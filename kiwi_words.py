from kiwi import Kiwi
from collections import Counter
import os
import pandas as pd

# Kiwi ì´ˆê¸°í™”
kiwi = Kiwi()

# ê³ ìœ ëª…ì‚¬ ëª©ë¡
custom_exceptions = [
    'ê°•ì°¬ì„', 'ì§€ë°•ë ¹', 'ê¹€ê·œë‚¨', 'ì¸ìŠ¤íƒ€', 'ìœ íŠœë¸Œ', 'ì˜¤ì¦ˆëª¨', 'ì£¼í˜„ì˜', 'ë‚¨ì¤‘ê·œ', 'ì„œìˆ˜ë¯¼',
    'í”„ë¡œëª¨ì…˜', 'í”„ë¡œì•¼êµ¬', 'í›ˆë‚¨', 'ê¸€ë¡œìŠ¤', 'íˆ¬ì–´ìŠ¤', 'ì†ë§ˆìŒ'
]

# ë¶„ì„í•  í’ˆì‚¬ (ì¼ë°˜ëª…ì‚¬, ê³ ìœ ëª…ì‚¬)
allowed_pos = {'NNG', 'NNP'}

# ë¶ˆìš©ì–´ ëª©ë¡
custom_stopwords = set([
    'ì˜', 'ê°€', 'ì´', 'ì€', 'ë“¤', 'ëŠ”', 'ì¢€', 'ì˜', 'ê±', 'ê³¼', 'ë„', 'ë¥¼',
    'ìœ¼ë¡œ', 'ì', 'ì—', 'ì™€', 'í•œ', 'í•˜ë‹¤', 'ì—ì„œ', 'ë¶€í„°', 'ê¹Œì§€', 'ê³ ',
    'ì…ë‹ˆë‹¤', 'ê·¸ë¦¬ê³ ', 'ê·¸', 'ê²ƒ', 'ìˆ˜', 'ë˜í•œ', 'ìˆëŠ”', 'ì—†ëŠ”', '(', ')', '.',
    '!', '?', 'ê¸€', 'ì˜¤ëŠ˜', 'ì˜ìƒ', 'ì§€ê¸ˆ', 'ë¬¸ì˜', 'ê°ì‚¬', 'ã…œã…œ', 'ã… ã… ', 'ã…‹ã…‹',
    'ë§í¬', 'ì¸', 'ìŠ¤íƒ€', 'íˆ¬', 'ìœ ', 'ì œì‘', 'ì°¸ì—¬', 'ì´ë²¤íŠ¸', 'ê¹€', 'ì „', 'ì‚¬ìš©',
])

# ê³ ìœ ëª…ì‚¬ ë³´í˜¸ìš© ì–¸ë”ìŠ¤ì½”ì–´ ë¶™ì´ê¸°
def preserve_proper_nouns(text, proper_nouns):
    if not isinstance(text, str):
        text = str(text) if isinstance(text, float) else ''
    for phrase in proper_nouns:
        text = text.replace(phrase, phrase + "_")
    return text

# ê³ ìœ ëª…ì‚¬ ë³‘í•© ì²˜ë¦¬
def merge_proper_nouns(result, custom_exceptions):
    merged = []
    for token in result:
        word, tag = token.form, token.tag
        if word.endswith("_"):  # ë³´í˜¸ëœ ê³ ìœ ëª…ì‚¬
            merged.append((word[:-1], 'NNP'))
        elif word in custom_exceptions:
            merged.append((word, 'NNP'))
        else:
            merged.append((word, tag))
    return merged

# í˜•íƒœì†Œ ë¶„ì„ í•¨ìˆ˜
def analyze_morphology(sentence):
    try:
        analyzed = kiwi.analyze(sentence)[0][0]  # ì²« ë²ˆì§¸ ê²°ê³¼ë§Œ ì‚¬ìš©
        filtered = [token for token in analyzed if token.tag in allowed_pos]
        return filtered
    except Exception as e:
        print(f"í˜•íƒœì†Œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return []

# íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
def get_file_list():
    data_folder = os.path.join(os.path.dirname(__file__), 'data')
    return os.listdir(data_folder) if os.path.exists(data_folder) else []

def csv_to_dataframe(file_name):
    data_folder = os.path.join(os.path.dirname(__file__), 'data')
    file_path = os.path.join(data_folder, file_name)
    if not os.path.exists(file_path): return None
    try:
        return pd.read_csv(file_path)
    except Exception as e:
        print(f"CSV ì½ê¸° ì˜¤ë¥˜: {e}")
        return None

def get_column_as_list(df, col_name):
    return df[col_name].tolist() if col_name in df.columns else []

# âœ… ë©”ì¸ ë¶„ì„ ì‹¤í–‰
if __name__ == "__main__":
    file_list = get_file_list()
    total_tokens = []

    for file_name in file_list:
        print(f"Processing: {file_name}")
        df = csv_to_dataframe(file_name)
        if df is None: continue

        titles = get_column_as_list(df, 'title')
        descriptions = get_column_as_list(df, 'description')

        for text in titles + descriptions:
            print(f"Analyzing: {text}")
            text = preserve_proper_nouns(text, custom_exceptions)
            tokens = analyze_morphology(text)
            merged = merge_proper_nouns(tokens, custom_exceptions)

            words = [
                word for word, pos in merged
                if word not in custom_stopwords
            ]
            total_tokens.extend(words)

    # ë¹ˆë„ìˆ˜ ì¶œë ¥
    freq = Counter(total_tokens)
    print("\nğŸ“Š ìì£¼ ë“±ì¥í•œ ë‹¨ì–´ Top 20:")
    for word, count in freq.most_common(20):
        print(f"{word}: {count}íšŒ")